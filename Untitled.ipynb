{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM,SimpleRNN,GRU\n",
    "from keras.datasets import imdb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 256\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train_L, y_train_L), (x_test_L, y_test_L) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train_L), 'train sequences')\n",
    "print(len(x_test_L), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 今回は学習データをランダムに50％まで減らす\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, _x, y_train, _y = train_test_split(x_train_L, y_train_L, test_size=0.5, random_state=42)\n",
    "x_test, _X, y_test, _Y = train_test_split(x_test_L, y_test_L, test_size=0.5, random_state=42)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (12500, 80)\n",
      "x_test shape: (12500, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 160s 13ms/step - loss: 0.7095 - acc: 0.5114 - val_loss: 0.6889 - val_acc: 0.5355\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 154s 12ms/step - loss: 0.6869 - acc: 0.5469 - val_loss: 0.6821 - val_acc: 0.5498\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 160s 13ms/step - loss: 0.6704 - acc: 0.5870 - val_loss: 0.6694 - val_acc: 0.5905\n",
      "12500/12500 [==============================] - 38s 3ms/step\n",
      "Test score: 0.6694292150878907\n",
      "Test accuracy: 0.5904799995231629\n"
     ]
    }
   ],
   "source": [
    "# SimpleRNN\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)#シーケンスを同じ長さになるように詰めます．\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))#固定長の分散表現に変換\n",
    "model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))#全結合\n",
    "\n",
    "# 異なるオプティマイザーと異なるオプティマイザー設定を使用してみてください\n",
    "model.compile(loss='binary_crossentropy',#2値分類のloss\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (12500, 80)\n",
      "x_test shape: (12500, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 463s 37ms/step - loss: 0.6231 - acc: 0.6501 - val_loss: 0.5230 - val_acc: 0.7486\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 445s 36ms/step - loss: 0.3847 - acc: 0.8338 - val_loss: 0.4380 - val_acc: 0.7983\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 447s 36ms/step - loss: 0.2618 - acc: 0.8988 - val_loss: 0.4667 - val_acc: 0.8070\n",
      "12500/12500 [==============================] - 117s 9ms/step\n",
      "Test score: 0.46665385058403014\n",
      "Test accuracy: 0.807040000076294\n"
     ]
    }
   ],
   "source": [
    "# GRU\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)#シーケンスを同じ長さになるように詰める（今回の1シーケンスは１レビュー．それを全レビューの中で最も単語数が多いシーケンスの長さに合わせる＝単語数をそろえる）\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))#正の整数（インデックス）を固定次元の密ベクトルに変換\n",
    "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))#全結合\n",
    "\n",
    "# 異なるオプティマイザーと異なるオプティマイザー設定を使用してみてください\n",
    "model.compile(loss='binary_crossentropy',#2値分類のloss\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
